{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb18e06-f012-42be-8c7b-b055850620e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176be048-2058-461e-a069-75602c3a120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from video_llama.common.config import Config\n",
    "from video_llama.common.dist_utils import get_rank\n",
    "from video_llama.common.registry import registry\n",
    "from video_llama.conversation.conversation_video import (\n",
    "    Chat, Conversation, default_conversation,SeparatorStyle,conv_llava_llama_2\n",
    ")\n",
    "import decord\n",
    "decord.bridge.set_bridge('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e461a1f7-c857-4be3-b61a-01fb60971b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_llama.datasets.builders import *\n",
    "from video_llama.models import *\n",
    "from video_llama.processors import *\n",
    "from video_llama.runners import *\n",
    "from video_llama.tasks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ce50ed-617d-4d38-baa6-2dfc1ff3d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d53eff-d36a-4a4d-8b01-d3bb3892dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aca0367-d168-4c16-b064-6f40942b96ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cfg_path': './eval_configs/video_llama_eval_only_vl_edited.yaml',\n",
       " 'model_type': 'llama_v2',\n",
       " 'gpu_id': 0,\n",
       " 'options': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = dict(\n",
    "    cfg_path=\"./eval_configs/video_llama_eval_only_vl_edited.yaml\",\n",
    "    model_type=\"llama_v2\",\n",
    "    gpu_id=0,\n",
    "    options=[],\n",
    ")\n",
    "args = AttrDict(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7b5f7-ecf1-40ca-b2a7-204c6c061709",
   "metadata": {},
   "source": [
    "#### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2cc1bff-a715-4eb5-a1e8-7b7fb26601c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e9a033-d507-4e94-a492-ed7dd3ef54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dcfbb8-0d60-449e-a3e2-0105f96a9a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/piyush/pretrained_checkpoints/LargeModels/VideoLLAMA/Video-LLaMA-2-7B-Pretrained/llama-2-7b-chat-hf/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.llama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26511173-5857-418a-9e97-068a0259f2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/piyush/pretrained_checkpoints/LargeModels/VideoLLAMA/Video-LLaMA-2-7B-Pretrained/VL_LLaMA_2_7B_Pretrained.pth'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6af2d42-7430-4f7e-8656-eca7368a1c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:36<00:00, 18.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load first Checkpoint: /work/piyush/pretrained_checkpoints/LargeModels/VideoLLAMA/Video-LLaMA-2-7B-Pretrained/VL_LLaMA_2_7B_Pretrained.pth\n"
     ]
    }
   ],
   "source": [
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408e5821-a745-46cc-bcbf-819879a2ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_processor_cfg = cfg.datasets_cfg.webvid.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fd025f-c9ff-4037-86bc-5057cd21d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c71adc-0832-43e3-9720-17e023217dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<video_llama.conversation.conversation_video.Chat at 0x7f3407802850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ee3d63-3f83-48ee-9062-64db551bf2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7851.579264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params = np.sum([p.numel() for p in model.parameters()])\n",
    "n_params / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abaebbb3-0846-4e65-bf63-65eb8edb549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./examples/birthday.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe97ba96-6282-4240-b0d4-cc0eff55da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_state = conv_llava_llama_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e6b434-dad7-4b24-95cf-b18d52723669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation(system='You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.', roles=('USER', 'ASSISTANT'), messages=[], offset=0, sep_style=<SeparatorStyle.LLAMA_2: 3>, sep='<s>', sep2='</s>', skip_next=False, conv_id=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "780ffa3a-a7e3-4019-8764-dc3e61b38729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./examples/birthday.mp4\n"
     ]
    }
   ],
   "source": [
    "chat_state.system =  \"You are able to understand the visual content that the user provides.\"\\\n",
    "    \"Follow the instructions carefully and explain your answers in detail.\"\n",
    "img_list = []\n",
    "llm_message = chat.upload_video_without_audio(video_path, chat_state, img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f6c76fe-3222-46a7-836e-5d431b871d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"What is this video showing?\"\n",
    "chat.ask(user_message, chat_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e20256-5012-46a5-876f-c1c8032988e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 1\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24869cdf-2e06-452b-98f5-bea806b7b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_message = chat.answer(\n",
    "    conv=chat_state,\n",
    "    img_list=img_list,\n",
    "    num_beams=num_beams,\n",
    "    temperature=temperature,\n",
    "    max_new_tokens=300,\n",
    "    max_length=2000,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "118764dc-3623-4591-817e-4b97a690f21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the frames provided in the video, it appears to be showing a young man sitting at a table with a laptop and a birthday cake. Here's a detailed explanation of each frame:\n",
      "0.0 seconds: The video starts with the man sitting at a table, wearing a blue shirt and a yellow party hat. He's looking directly at the camera with a smile on his face.\n",
      "2.1 seconds: The man reaches out and turns on the laptop.\n",
      "4.2 seconds: He starts typing on the laptop and looks up, as if he's checking something.\n",
      "6.2 seconds: The man types some more on the laptop and then leans back in his chair, looking relaxed.\n",
      "8.3 seconds: He types on the laptop and then looks up again, this time with a big smile on his face. He's probably excited about something.\n",
      "10.4 seconds: The man types on the laptop and then stands up, holding the laptop in one hand and the birthday cake in the other. He's probably getting ready to make a toast.\n",
      "12.5 seconds: The man raises the laptop and the birthday cake, both of which are decorated with balloons and streamers. He's probably taking a photo or making a video call.\n",
      "14.6 seconds: The man brings the laptop and the birthday cake closer\n"
     ]
    }
   ],
   "source": [
    "print(llm_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f168af-9fe9-4505-87af-7835bbdbfc9b",
   "metadata": {},
   "source": [
    "**Inference on a SSv2 video sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fc5c3b3-2b42-4e1a-a5b8-478f32229457",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../TimeBound.v1/sample_data/folding_paper.mp4\"\n",
    "assert os.path.exists(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a895d11e-4455-48e4-84a3-cc84cf0bda4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TimeBound.v1/sample_data/folding_paper.mp4\n"
     ]
    }
   ],
   "source": [
    "chat_state = conv_llava_llama_2.copy()\n",
    "chat_state.system =  \"You are able to understand the visual content that the user provides.\"\\\n",
    "    \"Follow the instructions carefully and explain your answers in detail.\"\n",
    "img_list = []\n",
    "llm_message = chat.upload_video_without_audio(video_path, chat_state, img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da722e12-c6ab-454a-87c9-4fb7a82e6f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the video provided, the correct option is (b) Someone folding a paper.\n",
      "\n",
      "In the video, we can see a person holding a white sheet of paper and folding it in a sequence of 8 frames. The person starts by taking the paper and folding it in half lengthwise, then folds it in half again, creating a crease in the middle. The person then folds the paper in half a third time, creating another crease. The video ends with the person holding the folded paper in their hand.\n",
      "Therefore, the correct option is (b) Someone folding a paper.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "    Given this video, you have to select which is the option that correctly describes the video.\n",
    "    (a) Someone unfolding a paper. (b) Someone folding a paper.\n",
    "\n",
    "    You have to only answer (a) or (b).\n",
    "\"\"\"\n",
    "chat.ask(user_message, chat_state)\n",
    "\n",
    "\n",
    "llm_message = chat.answer(\n",
    "    conv=chat_state,\n",
    "    img_list=img_list,\n",
    "    num_beams=num_beams,\n",
    "    temperature=temperature,\n",
    "    max_new_tokens=300,\n",
    "    max_length=2000,\n",
    ")[0]\n",
    "\n",
    "print(llm_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770295d-f3cb-47f5-9742-0388358a3227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
