{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5977164e-351f-48fd-909b-a44bb2bf4b27",
   "metadata": {},
   "source": [
    "A notebook to evaluate on the state-change subset of [`ViLMA`](https://arxiv.org/pdf/2311.07022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbea7e38-b7fc-4de8-80b1-6b304c653bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc88042-5300-4a30-a272-3e07cea3556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd149ba1-3b70-46ae-9cd2-a879438c7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_api import (\n",
    "    load_config, load_model, setup_seeds, ask_about_video,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d441a7-2375-41e0-8713-d50cd0b38988",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ecc52b-fc76-4eb9-acfe-ca2492dcb5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[:::] Loading model.\u001b[0m\n",
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth\n",
      "Loading Q-Former Done\n",
      "Loading LLAMA Tokenizer\n",
      "Loading LLAMA Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLAMA Done\n",
      "Loading LLAMA proj\n",
      "Loading llama_proj Done\n",
      "Load first Checkpoint: /work/piyush/pretrained_checkpoints/LargeModels/VideoLLAMA/Video-LLaMA-2-7B-Pretrained/VL_LLaMA_2_7B_Pretrained.pth\n",
      "[:::] Model has 7.852B parameters.\n",
      "\u001b[32m[:::] Model loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get config\n",
    "args, cfg = load_config()\n",
    "\n",
    "# Load model\n",
    "chat, model, vis_processor = load_model(args, cfg, low_resource=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f94d1-1ac3-4365-964e-f0d18c393b04",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a86cd59-f08d-488c-93e4-a4b63b3e30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing all videos\n",
    "video_dir = \"/scratch/shared/nfs2/piyush/datasets/ViLMA/videos\"\n",
    "\n",
    "# Directory containing metadata\n",
    "metad_dir = \"/users/piyush/projects/ViLMA/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7357124-ae7b-4242-b271-b3fb80a4949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> dict:\n",
    "    \"\"\"Helper to load json file\"\"\"\n",
    "    import json\n",
    "    with open(path, 'rb') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9d19e2c-2814-4721-8b39-c5ef72d90264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_task = \"change-state\"\n",
    "sub_task = \"prestate\"\n",
    "task_file = os.path.join(\n",
    "    metad_dir, f\"{main_task}-{sub_task}.json\"\n",
    ")\n",
    "assert os.path.join(task_file)\n",
    "task_data = load_json(task_file)\n",
    "len(task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3db11dce-2fda-4e62-a715-c53526ca2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change-state-action.json\tplot.md\n",
      "change-state-inverse.json\tplotter_helper.py\n",
      "change-state-poststate.json\tplotter.py\n",
      "change-state-prestate.json\tquva-proficiency-foils.json\n",
      "counting-easy-digits.json\tquva-templates.json\n",
      "counting-easy-digits-sec.json\tquva-templates-processed.json\n",
      "counting-easy-spelled-pts.json\trare-actions-noun-foils.json\n",
      "counting-easy-spelled-sec.json\trare-actions-verb-foils.json\n",
      "counting-hard-digits.json\trelations.json\n",
      "counting-hard-digits-sec.json\tSemantic_Role_Labelling_Data_annotated.json\n",
      "counting-hard-spelled-pts.json\tSemantic_Role_Labelling_Data.json\n",
      "counting-hard-spelled-sec.json\tSRL_Action_Replacement_Top_1000.json\n",
      "dummy.json\t\t\tSRL_Actor_Swapping.json\n"
     ]
    }
   ],
   "source": [
    "!ls $metad_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da1496d6-3c0b-4417-ae3d-4919e9755a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(task_data).T\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca406073-d41f-4dbd-8aba-0e26a499b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change_of_state\n",
       "uncover     20\n",
       "unfold      20\n",
       "reveal      20\n",
       "unroll      19\n",
       "fold        19\n",
       "            ..\n",
       "clean        1\n",
       "filtrate     1\n",
       "cut away     1\n",
       "leave        1\n",
       "use          1\n",
       "Name: count, Length: 93, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"change_of_state\"].apply(lambda x: x[\"verb\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11483165-1f69-4fcb-a57a-6861e0702d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change-state-prestate-0001    Initially, the athlete is in a lower position.\n",
       "change-state-prestate-0002    Initially, the athlete is in a lower position.\n",
       "change-state-prestate-0003    Initially, the athlete is in a lower position.\n",
       "change-state-prestate-0004    Initially, the athlete is in a lower position.\n",
       "change-state-prestate-0007    Initially, the athlete is in a lower position.\n",
       "                                                   ...                      \n",
       "change-state-prestate-0815           Initially, the pipe band are unwrapped.\n",
       "change-state-prestate-0817                  Initially, the box is unwrapped.\n",
       "change-state-prestate-0818          Initially, the spring roll is unwrapped.\n",
       "change-state-prestate-0820           Initially, the bamboo mat is unwrapped.\n",
       "change-state-prestate-0821                Initially, the dough is unwrapped.\n",
       "Name: caption, Length: 624, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d32eb61f-9e50-4d38-848e-feaa97a6c563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "foils\n",
       "1    624\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"foils\"].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075cba39-39a9-4dc5-9b6a-f98d869b9512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change-state-prestate-0001    [Initially, the athlete is in a higher position.]\n",
       "change-state-prestate-0002    [Initially, the athlete is in a higher position.]\n",
       "change-state-prestate-0003    [Initially, the athlete is in a higher position.]\n",
       "change-state-prestate-0004    [Initially, the athlete is in a higher position.]\n",
       "change-state-prestate-0007    [Initially, the athlete is in a higher position.]\n",
       "                                                    ...                        \n",
       "change-state-prestate-0815              [Initially, the pipe band are wrapped.]\n",
       "change-state-prestate-0817                     [Initially, the box is wrapped.]\n",
       "change-state-prestate-0818             [Initially, the spring roll is wrapped.]\n",
       "change-state-prestate-0820              [Initially, the bamboo mat is wrapped.]\n",
       "change-state-prestate-0821                   [Initially, the dough is wrapped.]\n",
       "Name: foils, Length: 624, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"foils\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf90dbb2-2a2d-490a-b37e-7ef477d4411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "coin                      235\n",
       "something-something-v2    195\n",
       "youcook2                  147\n",
       "star                       33\n",
       "RareAct                    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff6357ef-19f6-401f-aec2-f58846373816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset_idx.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4d9d868-624f-48b2-8eba-c4b7d98746ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 19), 0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add video ID to each row\n",
    "\n",
    "def get_video_id(item):\n",
    "    from_yt = ['RareAct', 'VidSitu', 'youcook2', 'coin']\n",
    "    # find the full path\n",
    "    dataset = item['dataset']\n",
    "    video_file = item['video_file']\n",
    "    # video_path = None\n",
    "    if dataset == 'QUVA':\n",
    "        normalized = item.get('normalized')\n",
    "        assert normalized\n",
    "        # video_dir = osp.join(self.quva_dir, 'normalized_videos')\n",
    "        # video_path = osp.join(video_dir, video_file)\n",
    "        video_id = video_file\n",
    "    elif dataset == 'something-something-v2':\n",
    "        # video_dir = self.something_something_dir\n",
    "        # video_path = osp.join(video_dir, f'{item[\"dataset_idx\"]}.webm')\n",
    "        video_id = item[\"dataset_idx\"]\n",
    "    elif dataset == 'star':\n",
    "        # video_dir = self.star_dir\n",
    "        # video_path = osp.join(video_dir, f\"{video_file}.mp4\")\n",
    "        video_id = video_file\n",
    "    elif dataset in from_yt:\n",
    "        # video_dir = self.youtube_dir\n",
    "        # video_path = osp.join(video_dir, f'{item[\"youtube_id\"]}.mp4')\n",
    "        video_id = item[\"youtube_id\"]\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented yet.')\n",
    "    return video_id\n",
    "\n",
    "video_ids = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].to_dict()\n",
    "    video_id = get_video_id(row)\n",
    "    video_ids.append(video_id)\n",
    "df[\"video_id\"] = video_ids\n",
    "\n",
    "df.shape, df.video_id.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a10b0ab-4d35-4f4a-8c5a-8fd5eeb423e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 20), 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_video_path(video_dir, video_id):\n",
    "    paths = glob(os.path.join(video_dir, f\"{video_id}.*\"))\n",
    "    assert len(paths) in [0, 1]\n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        path = paths[0]\n",
    "        return path\n",
    "\n",
    "\n",
    "df[\"video_path\"] = df[\"video_id\"].apply(\n",
    "    lambda x: search_video_path(video_dir, x)\n",
    ")\n",
    "df.shape, df.video_path.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab42c7af-83a3-4688-a90b-500d7864e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = df[df.video_path.apply(lambda x: os.path.exists(x) if x is not None else False)].copy()\n",
    "subdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0251c09-da0c-401a-afec-0a2279433080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the frames provided in the video, it appears that the athlete starts at a higher position and then performs a jump, landing on the ground. Therefore, the correct answer is (a) initially, the athlete is in a higher position.\n"
     ]
    }
   ],
   "source": [
    "# Test on a sample row\n",
    "i = 0\n",
    "row = subdf.iloc[i].to_dict()\n",
    "video_path = row[\"video_path\"]\n",
    "\n",
    "caption = row[\"caption\"].lower()\n",
    "foil = row[\"foils\"][0].lower()\n",
    "\n",
    "randomise_options = True\n",
    "enum_options = [\"(a)\", \"(b)\"]\n",
    "if randomise_options:\n",
    "    if np.random.uniform() < 0.5:\n",
    "        text_options = [caption, foil]\n",
    "        correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "    else:\n",
    "        text_options = [foil, caption]\n",
    "        correct_answer = f\"{enum_options[1]} {caption}\"\n",
    "user_message = \"Given this video, you have to select which is the option \"\\\n",
    "    \"that correctly describes the video: \"\\\n",
    "    f\"{enum_options[0]} {text_options[0]} \"\\\n",
    "    f\"{enum_options[1]} {text_options[1]} \"\\\n",
    "    f\"You have to only answer {enum_options[0]} or {enum_options[0]}.\"\n",
    "\n",
    "model_answer = ask_about_video(chat, video_path, user_message)\n",
    "print(model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc1b3b56-5668-45e6-a522-d4ce1fbc6eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answer in model_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ce549-fb93-426f-af46-7df979ee870d",
   "metadata": {},
   "source": [
    "**Evaluate on entire dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "100da1f3-8e94-4c2a-8755-1f5a2daebb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_row(row, verbose=False, randomise_options=True, enum_options=[\"(a)\", \"(b)\"]):\n",
    "    \"\"\"Checks a single row.\"\"\"\n",
    "\n",
    "    video_path = row[\"video_path\"]    \n",
    "    caption = row[\"caption\"].lower()\n",
    "    foil = row[\"foils\"][0].lower()\n",
    "    \n",
    "    if randomise_options:\n",
    "        if np.random.uniform() < 0.5:\n",
    "            text_options = [caption, foil]\n",
    "            correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "        else:\n",
    "            text_options = [foil, caption]\n",
    "            correct_answer = f\"{enum_options[1]} {caption}\"\n",
    "    else:\n",
    "        text_options = [caption, foil]\n",
    "        correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "\n",
    "    user_message = \"Given this video, you have to select which is the option \"\\\n",
    "        \"that correctly describes the video: \"\\\n",
    "        f\"{enum_options[0]} {text_options[0]} \"\\\n",
    "        f\"{enum_options[1]} {text_options[1]} \"\\\n",
    "        f\"You have to only answer {enum_options[0]} or {enum_options[0]}.\"\n",
    "    \n",
    "    model_answer = ask_about_video(chat, video_path, user_message)\n",
    "    flag = correct_answer in model_answer\n",
    "\n",
    "    if verbose:\n",
    "        print(\"QUESTION: \", user_message)\n",
    "        print(\"VIDEO: \", video_path)\n",
    "        print(\"MODEL ANSWER: \", model_answer)\n",
    "        print(\"IDEAL ANSWER: \", correct_answer)\n",
    "\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd66dd77-2eaa-45b4-a0b2-5c2449fc70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def tqdm_iterator(items, desc=None, bar_format=None, **kwargs):\n",
    "    tqdm._instances.clear()\n",
    "    iterator = tqdm(\n",
    "        items,\n",
    "        desc=desc,\n",
    "        bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',\n",
    "        **kwargs,\n",
    "    )\n",
    "    tqdm._instances.clear()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfe472-5a7c-46d7-8616-c7a43665c016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on entire dataset:   0%|          | 0/618 [00:00<?, ?it/s]                                                                                                             "
     ]
    }
   ],
   "source": [
    "\n",
    "iterator = tqdm_iterator(range(len(subdf)), desc=\"Evaluating on entire dataset\")\n",
    "flags = []\n",
    "failed = []\n",
    "for i in iterator:\n",
    "    row = subdf.iloc[i].to_dict()\n",
    "    try:\n",
    "        flag = check_row(row, verbose=False)\n",
    "    except:\n",
    "        # Failed on this video\n",
    "        failed.append(i)\n",
    "    flags.append(flag)\n",
    "flags = np.array(flags).astype(int)\n",
    "print(\"Accuracy: \", np.mean(flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a8cb4-4b6a-4bec-90d3-1d82a7f9eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84f643-7735-4a6a-bbf1-c119c543deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d86b1309-c6c8-4c55-bb93-0f4950a0aca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47572815533980584"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c123e-86fa-4deb-a507-38166d218578",
   "metadata": {},
   "source": [
    "**Run without shuffling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5639161-bcbd-464b-b57c-c1d9a7a70b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on entire dataset:   3%|▎         | 18/618 [03:16<1:37:58,  9.80s/it]                                                                                                  [h264 @ 0x94390500] mmco: unref short failure\n",
      "Evaluating on entire dataset:  23%|██▎       | 144/618 [24:29<1:16:11,  9.64s/it]                                                                                                 [h264 @ 0x943663c0] mmco: unref short failure\n",
      "Evaluating on entire dataset:  36%|███▌      | 222/618 [38:22<1:06:25, 10.07s/it]                                                                                                 [h264 @ 0x94330c40] mmco: unref short failure\n",
      "Evaluating on entire dataset:  46%|████▌     | 284/618 [48:37<56:58, 10.23s/it]                                                                                                   [mov,mp4,m4a,3gp,3g2,mj2 @ 0x94369d00] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x94369d00] moov atom not found\n",
      "Evaluating on entire dataset:  48%|████▊     | 297/618 [50:34<1:05:42, 12.28s/it]                                                                                                 [mov,mp4,m4a,3gp,3g2,mj2 @ 0x91edb280] moov atom not found\n",
      "Evaluating on entire dataset:  54%|█████▍    | 335/618 [57:14<46:43,  9.91s/it]                                                                                                   "
     ]
    }
   ],
   "source": [
    "iterator = tqdm_iterator(range(len(subdf)), desc=\"Evaluating on entire dataset\")\n",
    "flags = []\n",
    "failed = []\n",
    "for i in iterator:\n",
    "    row = subdf.iloc[i].to_dict()\n",
    "    try:\n",
    "        flag = check_row(row, verbose=False, randomise_options=False)\n",
    "    except:\n",
    "        # Failed on this video\n",
    "        failed.append(i)\n",
    "    flags.append(flag)\n",
    "flags = np.array(flags).astype(int)\n",
    "print(\"Accuracy: \", np.mean(flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40be4c8d-8861-4aa2-af14-f69d405273d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dc55bf8-af38-47be-a519-e61868240934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9352750809061489\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.mean(flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd840d-2a4d-4635-8d09-1483e77c1a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
